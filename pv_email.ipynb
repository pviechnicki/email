{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Project: Import emails exported from outlook via csv into DOTCE, classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Go to correct directory and activate the DOTCE virtual env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pviechnicki\\Desktop\\pviechnicki_home\\sandbox\\state\\dotce\n",
      "# conda environments:\n",
      "#\n",
      "dotce                    C:\\Users\\pviechnicki\\AppData\\Local\\Continuum\\Anaconda3\\envs\\dotce\n",
      "root                  *  C:\\Users\\pviechnicki\\AppData\\Local\\Continuum\\Anaconda3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd c:\\Users\\pviechnicki\\Desktop\\pviechnicki_home\\sandbox\\state\\dotce\n",
    "%pwd\n",
    "! activate dotce\n",
    "! conda info --envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read csv file of emails into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe contains 4629 messages\n",
      "Non-empty datafram contains 463messages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Make sure we're in the right directory\n",
    "os.getcwd()\n",
    "email_df = pd.read_csv('C:\\\\Users\\\\pviechnicki\\\\Desktop\\\\pviechnicki_home\\\\sandbox\\\\state\\\\data\\\\pv_email\\\\combined_emails.csv', sep='|')\n",
    "#Add rowid\n",
    "email_df['rownum'] = range(0, len(email_df))\n",
    "email_df.groupby('cat').count()\n",
    "# Filter out empty rows\n",
    "non_empty_df = email_df[email_df['body'].isnull() == False].sample(frac=.1)\n",
    "#sample method chooses a random sample of the origina frame\n",
    "#https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "print(\"Original dataframe contains {} messages\\nNon-empty datafram contains {} messages\\n\".format(\n",
    "len(email_df), len(non_empty_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract features from text document corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\pviechnicki\\\\AppData\\\\Local\\\\Continuum\\\\Anaconda3\\\\envs\\\\dotce\\\\lib\\\\site-packages\\\\pyLDAvis')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##From https://stackoverflow.com/questions/20078816/replace-non-ascii-characters-with-a-single-space\n",
    "###Purpose of this is because some messages in email archive had empty bodies and\n",
    "###pandas read them as float type NAN which threw an error\n",
    "from unidecode import unidecode\n",
    "def remove_non_ascii(text, rowid):\n",
    "    if (type(text) != str):\n",
    "        sys.stderr.write(\"Found a non-string at row {}, {}\\n\".format(rowid, text))\n",
    "    temp = str(text)\n",
    "    return \"\".join(s for s in temp if ord(s) < 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Let's make sure we can tokenize these properly and remove stop words\n",
    "<p>from <a href=\"http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\">CS Duke.edu</a></p>\n",
    "<p>Make sure you've installed the english punctuation and stop words list \n",
    "following <a href=\"http://www.nltk.org/data.html\">these instructions.</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('put', 2), ('mahesh', 1), ('registri', 1), ('research', 1), ('team', 1), ('peter', 1), ('may', 1), ('end', 1), ('drop', 1), ('nowrespons', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "snowballStemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "def preprocess(text):\n",
    "    no_punctuation_text = ''\n",
    "    if (type(text)== str):\n",
    "        lower_text = text.lower()\n",
    "        no_punctuation_text = lower_text.translate({ord(c):'' for c in string.punctuation})\n",
    "    return no_punctuation_text\n",
    "\n",
    "def myTokenize(text):\n",
    "    global snowballStemmer\n",
    "    tokens = []\n",
    "    cleaned = preprocess(text)\n",
    "    tokens = nltk.word_tokenize(cleaned)\n",
    "    filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    stemmed = [w for w in map(snowballStemmer.stem, filtered)]\n",
    "    return stemmed\n",
    "    \n",
    "tokens = myTokenize(email_df['body'][0])\n",
    "count = Counter(tokens)\n",
    "print(count.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: convert to term X document representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Instantiate a TFidf vectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, encoding='utf-8', \n",
    "                             max_df=0.5, tokenizer=myTokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "future_of_work         190\n",
       "fraud_waste_abuse      138\n",
       "mission_analytics      117\n",
       "workforce_analytics     18\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a vector of class labels\n",
    "class_labels = non_empty_df['cat']\n",
    "#use value_counts() method of series\n",
    "class_labels.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This step can take a while\n",
    "tfidf_matrix = vectorizer.fit_transform(non_empty_df['body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save feature names in a separate list\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 6: Check counts for specific terms\n",
    "<p><i>Not worth doing this on larger corpora -- too slow!</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing email # 100\n",
      "Processing email # 200\n",
      "Processing email # 300\n",
      "Processing email # 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('us', 5312), ('arlington', 2462), ('peter', 1768), ('sent', 1126), ('viechnicki', 1055), ('mumbai', 800), ('1', 797), ('subject', 677), ('data', 610), ('mailtopviechnickideloittecom', 604)]\n"
     ]
    }
   ],
   "source": [
    "##Instantiate a new counter and count frequencies of the tokens\n",
    "c = Counter()\n",
    "lineNo = 0\n",
    "for text in non_empty_df['body'].tolist():\n",
    "    lineNo += 1\n",
    "    tokens = myTokenize(text)\n",
    "    c.update(tokens)\n",
    "    if (lineNo % 100 == 0):\n",
    "        sys.stderr.write(\"Processing email # {}\\n\".format(lineNo))\n",
    "print(c.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 7: A better way of compiling the vocabulary\n",
    "<a href=\"http://nlpforhackers.io/tf-idf/\">Source http://nlpforhackers.io/tf-idf/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 11634\n",
      "Documents Count: 463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary in one pass\n",
    "vocabulary = set()\n",
    "for text in non_empty_df['body']:\n",
    "    words = myTokenize(text)\n",
    "    vocabulary.update(words)\n",
    " \n",
    "vocabulary = list(vocabulary)\n",
    "word_index = {w: idx for idx, w in enumerate(vocabulary)}\n",
    " \n",
    "VOCABULARY_SIZE = len(vocabulary)\n",
    "DOCUMENTS_COUNT = len(non_empty_df.index)\n",
    " \n",
    "print(\"Vocabulary size: {}\\nDocuments Count: {}\\n\".format(\n",
    "    VOCABULARY_SIZE, DOCUMENTS_COUNT))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Let's look more closely at the features that have high tf-idf scores\n",
    "<p>Tip of the hat to this blog: <a href=\"https://buhrmann.github.io/tfidf-analysis.html\">blog post from Thomas Buhrmann</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Returns top n tfidf features as df, but takes dense format vector as input\n",
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "#convert single row into dense format\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mailtoweggers38gmailcom</td>\n",
       "      <td>0.475205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>839</td>\n",
       "      <td>0.424112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tn</td>\n",
       "      <td>0.394224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0.283355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weggersdeloittecomsubject</td>\n",
       "      <td>0.278087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>octob</td>\n",
       "      <td>0.270831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>egger</td>\n",
       "      <td>0.239569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>william</td>\n",
       "      <td>0.237561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.233639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tuesday</td>\n",
       "      <td>0.153122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature     tfidf\n",
       "0    mailtoweggers38gmailcom  0.475205\n",
       "1                        839  0.424112\n",
       "2                         tn  0.394224\n",
       "3                         27  0.283355\n",
       "4  weggersdeloittecomsubject  0.278087\n",
       "5                      octob  0.270831\n",
       "6                      egger  0.239569\n",
       "7                    william  0.237561\n",
       "8                       2015  0.233639\n",
       "9                    tuesday  0.153122"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is showing us the top ten tfidf scores for document 3\n",
    "top_feats_in_doc(tfidf_matrix, feature_names, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seattl</td>\n",
       "      <td>0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>0.009809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>india</td>\n",
       "      <td>0.009113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>junko</td>\n",
       "      <td>0.008851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7142</td>\n",
       "      <td>0.008495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jake</td>\n",
       "      <td>0.007699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>teldirect</td>\n",
       "      <td>0.007575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mission</td>\n",
       "      <td>0.007510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>join</td>\n",
       "      <td>0.007279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>slide</td>\n",
       "      <td>0.007188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pankaj</td>\n",
       "      <td>0.007074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>april</td>\n",
       "      <td>0.006859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fraud</td>\n",
       "      <td>0.006798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai</td>\n",
       "      <td>0.006615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iphon</td>\n",
       "      <td>0.006570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dan</td>\n",
       "      <td>0.006406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>steven</td>\n",
       "      <td>0.006199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cathryn</td>\n",
       "      <td>0.006020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kaji</td>\n",
       "      <td>0.005784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>brien</td>\n",
       "      <td>0.005730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ohio</td>\n",
       "      <td>0.005727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>interact</td>\n",
       "      <td>0.005583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chatbot</td>\n",
       "      <td>0.005531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cell</td>\n",
       "      <td>0.005530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.005513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     tfidf\n",
       "0      seattl  0.009854\n",
       "1          91  0.009809\n",
       "2       india  0.009113\n",
       "3       junko  0.008851\n",
       "4        7142  0.008495\n",
       "5        jake  0.007699\n",
       "6   teldirect  0.007575\n",
       "7     mission  0.007510\n",
       "8        join  0.007279\n",
       "9       slide  0.007188\n",
       "10     pankaj  0.007074\n",
       "11      april  0.006859\n",
       "12      fraud  0.006798\n",
       "13         ai  0.006615\n",
       "14      iphon  0.006570\n",
       "15        dan  0.006406\n",
       "16     steven  0.006199\n",
       "17    cathryn  0.006020\n",
       "18       kaji  0.005784\n",
       "19      brien  0.005730\n",
       "20       ohio  0.005727\n",
       "21   interact  0.005583\n",
       "22    chatbot  0.005531\n",
       "23       cell  0.005530\n",
       "24       2015  0.005513"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Helper function to calculate top n features that are on average most important among\n",
    "#documents with grp_ids = ?\n",
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)\n",
    "\n",
    "#Top features for entire corpus\n",
    "top_mean_feats(tfidf_matrix, feature_names, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_feats_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return a list of dfs, where each df holds top_n features and their mean tfidf value\n",
    "        calculated across documents with the same class label. '''\n",
    "    dfs = []\n",
    "    labels = ['fraud_waste_abuse']\n",
    "    for label in labels:\n",
    "        ids = np.where(y.cat==label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                             feature     tfidf\n",
       " 0                               jake  0.025829\n",
       " 1                              fraud  0.022808\n",
       " 2                              brien  0.019223\n",
       " 3                                dan  0.018991\n",
       " 4                            graphic  0.016865\n",
       " 5                               wast  0.016769\n",
       " 6                             steven  0.015194\n",
       " 7                               troy  0.015120\n",
       " 8                               abus  0.014870\n",
       " 9                              olson  0.014731\n",
       " 10                        punzenberg  0.014698\n",
       " 11                            pulkit  0.013977\n",
       " 12      httpgovernment2020dupresscom  0.013881\n",
       " 13                           program  0.013717\n",
       " 14                               fwa  0.013497\n",
       " 15  httpwwwsolutionrevolutionbookcom  0.013406\n",
       " 16                           crystal  0.013276\n",
       " 17                             iphon  0.012985\n",
       " 18                          interact  0.012121\n",
       " 19                        minneapoli  0.011778\n",
       " 20                            murphi  0.011647\n",
       " 21          mailtotbishopdeloittecom  0.011279\n",
       " 22                               wfe  0.011054\n",
       " 23                            lorenz  0.010823\n",
       " 24                           version  0.010657]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_by_class(tfidf_matrix, non_empty_df, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dotce",
   "language": "python",
   "name": "dotce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
