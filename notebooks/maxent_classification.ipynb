{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure out how to use maxent models to classify text\n",
    "<a href=\"https://web.stanford.edu/class/cs124/lec/Maximum_Entropy_Classifiers.pdf\">Inspiration from Chris Manning tutorial</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### following these pages:<br>\n",
    "<a href=\"http://www.nltk.org/api/nltk.classify.html#module-nltk.classify.scikitlearn\">How to wrap a sklearn SGDClassifier into an NLTK classifier</a><br>\n",
    "<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\">Details of the sklearn Stochastic Gradient Descent classifier</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test data\n",
    "### for a two-way classification problem, Location or Drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [('in Arcadia', 'LOCATION'),\n",
    "         (u'in Qu\\u00E9bec', 'LOCATION'),\n",
    "        ('taking Zantac', 'DRUG'),\n",
    "         ('outside Beynac', \"LOCATION\")]\n",
    "test = [('buying aspirin', 'DRUG'),\n",
    "       ('taking Prozac', 'DRUG'),\n",
    "       ('in Capetown', 'LOCATION')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in QuÃ©bec\n"
     ]
    }
   ],
   "source": [
    "print(train[1][0])\n",
    "# Make sure we're putting in the accented characters properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(previousWord, targetWord):\n",
    "    #True iff C = Location and w-1 is 'in' and isCapitalized(w)\n",
    "    if previousWord.lower() == 'in' and targetWord[0].isupper():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def f2(previousWord, targetWord):\n",
    "    latin1_lowerbound = int(\"0080\", 16) #i.e. 128\n",
    "    latin1_upperbound =  int(\"00FF\", 16) # i.e. 255\n",
    "    #True iff C= Location and hasAccentedLatinChar(w)\n",
    "    for char in targetWord:\n",
    "        if ord(char) >= latin1_lowerbound and ord(char) <= latin1_upperbound:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def f3(previousWord, targetWord):\n",
    "    #True iff C=Drug and endsWith(w, \"c\")\n",
    "    if (targetWord.lower().endswith('c')):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    " \n",
    "vectorFuncs = [f1, f2, f3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature X doc matrix from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[True, False, False], [True, True, True], [False, False, True], [False, False, True]]\n",
      "['LOCATION', 'LOCATION', 'DRUG', 'LOCATION']\n"
     ]
    }
   ],
   "source": [
    "#Function to vectorize a list of two-word phrases with three features\n",
    "def vectorize(labeledStrings, myVectorFuncs):\n",
    "    '''\n",
    "    Pass it a list of tuples of strings and class labels\n",
    "    get back a list of feature vectors and a list of class labels\n",
    "    '''\n",
    "    vectorMatrix = []\n",
    "    class_labels = []\n",
    "   \n",
    "    for (phrase, category) in labeledStrings:\n",
    "        class_labels.append(category)\n",
    "        tokens = word_tokenize(phrase)\n",
    "        vector = []\n",
    "        assert(len(tokens) == 2)\n",
    "        for i in [0,1,2]:\n",
    "            vector.append(myVectorFuncs[i](tokens[0], tokens[1]))\n",
    "        vectorMatrix.append(vector)\n",
    "    \n",
    "    return (vectorMatrix, class_labels)\n",
    "\n",
    "#Make sure it worked as expected\n",
    "train_X, class_labels_train = vectorize(train, vectorFuncs)\n",
    "print(train_X)\n",
    "print(class_labels_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False, False, False], [False, False, True], [True, False, False]]\n",
      "['DRUG', 'DRUG', 'LOCATION']\n"
     ]
    }
   ],
   "source": [
    "#Vectorize test data, check result makes sense\n",
    "test_X, class_labels_test = vectorize(test)\n",
    "print(test_X)\n",
    "print(class_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and train maxent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"log\", max_iter = 1000)\n",
    "#The loss=\"log\" parameter specifies a logistic regression model, not an SVM classifier\n",
    "# the max_iter supposedly is the number of iterations of training used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=1000, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_X, class_labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LOCATION', 'LOCATION', 'LOCATION'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'average': False,\n",
       " 'class_weight': None,\n",
       " 'epsilon': 0.1,\n",
       " 'eta0': 0.0,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 0.15,\n",
       " 'learning_rate': 'optimal',\n",
       " 'loss': 'log',\n",
       " 'max_iter': 1000,\n",
       " 'n_iter': None,\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'tol': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the coefficients for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76170401,  1.4276586 , -1.53987417]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the coefficients of the model\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.23263415])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the model intercept\n",
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.79559432e-02,   9.62044057e-01],\n",
       "       [  1.55413221e-01,   8.44586779e-01],\n",
       "       [  9.16219317e-04,   9.99083781e-01]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we replicate the predicted probabilities from the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9620440567724402\n"
     ]
    }
   ],
   "source": [
    "#prob(input = location) = 1 / 1 + e ^^ -z\n",
    "#z = B0 + B1X1 + ... BnXn\n",
    "from math import exp\n",
    "from functools import reduce\n",
    "#ez = exp(-(clf.intercept_ + ([(clf.coef_[0][i] * test_X[0][i]) + (clf.coef_[0][1] * test_X[0][1]) + (clf.coef_[0][2] * test_X[0][2])))\n",
    "ez = exp(-(clf.intercept_ + sum([(clf.coef_[0][i] * test_X[0][i]) for i in range(0, len(vectorFuncs))])))\n",
    "predict_1 = (1 / (1 + ez))\n",
    "print(predict_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.discrete.discrete_model as sm2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  response\n",
      "0  LOCATION         1\n",
      "1  LOCATION         1\n",
      "2      DRUG         0\n",
      "3  LOCATION         1\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame.from_records(train_X, columns=['f1', 'f2', 'f3'])\n",
    "class_labels_df = pd.DataFrame(class_labels_train, columns=['label'])\n",
    "class_labels_df['response'] = 0\n",
    "class_labels_df.loc[class_labels_df['label'] == 'LOCATION','response'] = 1\n",
    "print(class_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(class_labels_df['response'], train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.346574\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pviechnicki\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               response   No. Observations:                    4\n",
      "Model:                          Logit   Df Residuals:                        1\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 24 Apr 2018   Pseudo R-squ.:                  0.3837\n",
      "Time:                        15:12:33   Log-Likelihood:                -1.3863\n",
      "converged:                      False   LL-Null:                       -2.2493\n",
      "                                        LLR p-value:                    0.4219\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            27.3061    8.5e+05   3.21e-05      1.000   -1.67e+06    1.67e+06\n",
      "x2             3.0167   3.94e+06   7.67e-07      1.000   -7.71e+06    7.71e+06\n",
      "x3          1.353e-13      1.414   9.56e-14      1.000      -2.772       2.772\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.50 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
