{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure out how to use maxent models to classify text\n",
    "<a href=\"https://web.stanford.edu/class/cs124/lec/Maximum_Entropy_Classifiers.pdf\">Inspiration from Chris Manning tutorial</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### following these pages:<br>\n",
    "<a href=\"http://www.nltk.org/api/nltk.classify.html#module-nltk.classify.scikitlearn\">How to wrap a sklearn SGDClassifier into an NLTK classifier</a><br>\n",
    "<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\">Details of the sklearn Stochastic Gradient Descent classifier</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and test data\n",
    "### for a two-way classification problem, Location or Drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [('in Arcadia', 'LOCATION'),\n",
    "         (u'in Qu\\u00E9bec', 'LOCATION'),\n",
    "        ('taking Zantac', 'DRUG'),\n",
    "         ('outside Beynac', \"LOCATION\")]\n",
    "test = [('buying aspirin', 'DRUG'),\n",
    "       ('taking Prozac', 'DRUG'),\n",
    "       ('in Capetown', 'LOCATION')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in QuÃ©bec\n"
     ]
    }
   ],
   "source": [
    "print(train[1][0])\n",
    "# Make sure we're putting in the accented characters properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(previousWord, targetWord):\n",
    "    #True iff C = Location and w-1 is 'in' and isCapitalized(w)\n",
    "    if previousWord.lower() == 'in' and targetWord[0].isupper():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def f2(previousWord, targetWord):\n",
    "    latin1_lowerbound = int(\"0080\", 16) #i.e. 128\n",
    "    latin1_upperbound =  int(\"00FF\", 16) # i.e. 255\n",
    "    #True iff C= Location and hasAccentedLatinChar(w)\n",
    "    for char in targetWord:\n",
    "        if ord(char) >= latin1_lowerbound and ord(char) <= latin1_upperbound:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def f3(previousWord, targetWord):\n",
    "    #True iff C=Drug and endsWith(w, \"c\")\n",
    "    if (targetWord.lower().endswith('c')):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create feature X doc matrix from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[True, False, False], [True, True, True], [False, False, True], [False, False, True]]\n",
      "['LOCATION', 'LOCATION', 'DRUG', 'LOCATION']\n"
     ]
    }
   ],
   "source": [
    "#Function to vectorize a list of two-word phrases with three features\n",
    "def vectorize(labeledStrings):\n",
    "    '''\n",
    "    Pass it a list of tuples of strings and class labels\n",
    "    get back a list of feature vectors and a list of class labels\n",
    "    '''\n",
    "    vectorMatrix = []\n",
    "    class_labels = []\n",
    "    vectorFuncs = [f1, f2, f3]\n",
    "    for (phrase, category) in labeledStrings:\n",
    "        class_labels.append(category)\n",
    "        tokens = word_tokenize(phrase)\n",
    "        vector = []\n",
    "        assert(len(tokens) == 2)\n",
    "        for i in [0,1,2]:\n",
    "            vector.append(vectorFuncs[i](tokens[0], tokens[1]))\n",
    "        vectorMatrix.append(vector)\n",
    "    \n",
    "    return (vectorMatrix, class_labels)\n",
    "\n",
    "#Make sure it worked as expected\n",
    "train_X, class_labels_train = vectorize(train)\n",
    "print(train_X)\n",
    "print(class_labels_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False, False, False], [False, False, True], [True, False, False]]\n",
      "['DRUG', 'DRUG', 'LOCATION']\n"
     ]
    }
   ],
   "source": [
    "#Vectorize test data, check result makes sense\n",
    "test_X, class_labels_test = vectorize(test)\n",
    "print(test_X)\n",
    "print(class_labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and train maxent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss=\"log\", max_iter = 1000)\n",
    "#The loss=\"log\" parameter specifies a logistic regression model, not an SVM classifier\n",
    "# the max_iter supposedly is the number of iterations of training used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=1000, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_X, class_labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LOCATION', 'LOCATION', 'LOCATION'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'average': False,\n",
       " 'class_weight': None,\n",
       " 'epsilon': 0.1,\n",
       " 'eta0': 0.0,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 0.15,\n",
       " 'learning_rate': 'optimal',\n",
       " 'loss': 'log',\n",
       " 'max_iter': 1000,\n",
       " 'n_iter': None,\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'tol': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the coefficients for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.10058785,  2.66455433, -1.78222997]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the coefficients of the model\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.40340975])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the model intercept\n",
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.21890715e-02,   9.67810928e-01],\n",
       "       [  1.65042229e-01,   8.34957771e-01],\n",
       "       [  2.02615547e-04,   9.99797384e-01]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we replicate the predicted probabilities from the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9678109284919212\n"
     ]
    }
   ],
   "source": [
    "#prob(input = location) = 1 / 1 + e ^^ -z\n",
    "#z = B0 + B1X1 + ... BnXn\n",
    "from math import exp\n",
    "ez = exp(-(clf.intercept_ + (clf.coef_[0][0] * test_X[0][0]) + (clf.coef_[0][1] * test_X[0][1]) + (clf.coef_[0][2] * test_X[0][2])))\n",
    "predict_1 = (1 / (1 + ez))\n",
    "print(predict_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
