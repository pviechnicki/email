{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body sensitivity\n",
      "0                                    lets grab lunch    Personal\n",
      "1               I have a meeting with the ambassador    Official\n",
      "2        Attached are meeting notes about the report    Official\n",
      "3                   The ambassador is arriving today    Official\n",
      "4  We have a lunch date today but my daughter is ...    Personal\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/embicks/Documents/DOTCE/email_marker/email/data/Input/svm_test.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5\n",
       "True     4\n",
       "Name: personal, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add new column to dataframe with True if sensitivity == personal\n",
    "#Edit the column names and truth conditions to match your data\n",
    "data['personal'] = (data['sensitivity'] == 'Personal')\n",
    "#Create a vector of class labels\n",
    "class_labels = data['personal']\n",
    "#use value_counts() method of series\n",
    "class_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body sensitivity  personal\n",
      "5          Where would you like to go to lunch today    Personal      True\n",
      "6                     What time is the meeting today    Official     False\n",
      "7                        There is a report due today    Official     False\n",
      "8  My son is sick so I will be staying home today...    Personal      True\n",
      "                                                body sensitivity  personal\n",
      "0                                    lets grab lunch    Personal      True\n",
      "1               I have a meeting with the ambassador    Official     False\n",
      "2        Attached are meeting notes about the report    Official     False\n",
      "3                   The ambassador is arriving today    Official     False\n",
      "4  We have a lunch date today but my daughter is ...    Personal      True\n"
     ]
    }
   ],
   "source": [
    "train_df = data.iloc[:5]\n",
    "test_df = data.iloc[5:]\n",
    "class_labels_training = list(train_df['personal'])\n",
    "class_labels_test = list(test_df['personal'])\n",
    "value_counts = nltk.FreqDist(class_labels_training)\n",
    "print(test_df)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snowballStemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "def preprocess(text):\n",
    "    no_punctuation_text = ''\n",
    "    if (type(text)== str):\n",
    "        lower_text = text.lower()\n",
    "        no_punctuation_text = lower_text.translate({ord(c):'' for c in string.punctuation})\n",
    "    return no_punctuation_text\n",
    "\n",
    "def myTokenize(text):\n",
    "    global snowballStemmer\n",
    "    tokens = []\n",
    "    cleaned = preprocess(text)\n",
    "    tokens = nltk.word_tokenize(cleaned)\n",
    "    filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "    stemmed = [w for w in map(snowballStemmer.stem, filtered)]\n",
    "    return stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define vocabulary\n",
    "vocabulary = ['lunch', 'today', 'sick', 'meeting', 'time', 'home', 'ambassador']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lunch': 1.6931471805599454, 'today': 1.6931471805599454, 'sick': 2.09861228866811, 'meeting': 2.791759469228055, 'time': 2.791759469228055, 'home': 2.791759469228055, 'ambassador': 1.6931471805599454}\n"
     ]
    }
   ],
   "source": [
    "##Instantiate a TFidf vectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, encoding='utf-8', \n",
    "                             max_df=0.5, tokenizer=myTokenize, vocabulary = vocabulary)\n",
    "train_X = vectorizer.fit_transform(train_df['body'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "idf = vectorizer.idf_\n",
    "word_weight_dict = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "print(word_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train svm model\n",
    "model_svm = SVC(kernel = 'linear', probability=True)\n",
    "model_svm.fit(train_X, class_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False]\n"
     ]
    }
   ],
   "source": [
    "#get predictions from svm model\n",
    "test_X = vectorizer.fit_transform(test_df['body'])\n",
    "test_word_weight_dict = dict(zip(vectorizer.get_feature_names(), idf))\n",
    "predictions = model_svm.predict( test_X )\n",
    "predict_probs = model_svm.predict_proba(test_X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ambassador': -0.65203996377860873, 'today': -0.12026771005052994, 'home': 0.0, 'meeting': 0.0, 'time': 0.0, 'sick': 0.65911800182510549, 'lunch': 1.4538960137130488}\n"
     ]
    }
   ],
   "source": [
    "#get feature coefficients from model\n",
    "coef = model_svm.coef_.toarray()\n",
    "top_coefficients = sorted(zip(coef[0], feature_names))\n",
    "coefficient_dict = {}\n",
    "for coef, word in top_coefficients:\n",
    "    coefficient_dict[word] = coef\n",
    "print(coefficient_dict)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[True, 2.2580290022611367], [False, -0.20363093418445577], [False, -0.20363093418445577], [True, 1.1796022041280805]]\n"
     ]
    }
   ],
   "source": [
    "#manually calculate predictions from tfidf scores and model coefficients\n",
    "predictions = []\n",
    "for i, row in test_df.iterrows():\n",
    "    predict_val = 0\n",
    "    message = row['body']\n",
    "    text= myTokenize(message)\n",
    "    for word in text:\n",
    "        try:\n",
    "            model_coef = coefficient_dict[word]\n",
    "            tfidf_score = word_weight_dict[word]\n",
    "            word_score = model_coef*tfidf_score\n",
    "            predict_val += word_score\n",
    "        except:\n",
    "            predict_val += 0\n",
    "    if predict_val >0 :\n",
    "        prediction = True\n",
    "    else:\n",
    "        prediction = False\n",
    "    predictions.append([prediction, predict_val])\n",
    "print(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.886547629787\n",
      "  (0, 1)\t0.46263733109\n",
      "  (1, 1)\t0.46263733109\n",
      "  (1, 4)\t0.886547629787\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t0.346181611599\n",
      "  (3, 2)\t0.663384613852\n",
      "  (3, 5)\t0.663384613852\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
